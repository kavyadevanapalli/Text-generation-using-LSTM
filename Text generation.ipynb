{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading text file\n",
    "\n",
    "filename = \"shakespear.txt\"\n",
    "raw_txt = open(filename, \"r\").read()\n",
    "raw_txt = raw_txt.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " \"'\": 3,\n",
       " ',': 4,\n",
       " '-': 5,\n",
       " '.': 6,\n",
       " ':': 7,\n",
       " ';': 8,\n",
       " '?': 9,\n",
       " 'a': 10,\n",
       " 'b': 11,\n",
       " 'c': 12,\n",
       " 'd': 13,\n",
       " 'e': 14,\n",
       " 'f': 15,\n",
       " 'g': 16,\n",
       " 'h': 17,\n",
       " 'i': 18,\n",
       " 'j': 19,\n",
       " 'k': 20,\n",
       " 'l': 21,\n",
       " 'm': 22,\n",
       " 'n': 23,\n",
       " 'o': 24,\n",
       " 'p': 25,\n",
       " 'q': 26,\n",
       " 'r': 27,\n",
       " 's': 28,\n",
       " 't': 29,\n",
       " 'u': 30,\n",
       " 'v': 31,\n",
       " 'w': 32,\n",
       " 'x': 33,\n",
       " 'y': 34,\n",
       " 'z': 35}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create mapping of all unique chars to integers\n",
    "\n",
    "chars = sorted(list(set(raw_txt)))\n",
    "char_to_int = dict([(c, i) for i, c in enumerate(chars)])\n",
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\n',\n",
       " 1: ' ',\n",
       " 2: '!',\n",
       " 3: \"'\",\n",
       " 4: ',',\n",
       " 5: '-',\n",
       " 6: '.',\n",
       " 7: ':',\n",
       " 8: ';',\n",
       " 9: '?',\n",
       " 10: 'a',\n",
       " 11: 'b',\n",
       " 12: 'c',\n",
       " 13: 'd',\n",
       " 14: 'e',\n",
       " 15: 'f',\n",
       " 16: 'g',\n",
       " 17: 'h',\n",
       " 18: 'i',\n",
       " 19: 'j',\n",
       " 20: 'k',\n",
       " 21: 'l',\n",
       " 22: 'm',\n",
       " 23: 'n',\n",
       " 24: 'o',\n",
       " 25: 'p',\n",
       " 26: 'q',\n",
       " 27: 'r',\n",
       " 28: 's',\n",
       " 29: 't',\n",
       " 30: 'u',\n",
       " 31: 'v',\n",
       " 32: 'w',\n",
       " 33: 'x',\n",
       " 34: 'y',\n",
       " 35: 'z'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_char = dict([(i, c) for i, c in enumerate(chars)])\n",
    "int_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99993"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_char = len(raw_txt)\n",
    "n_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocabs = len(chars)\n",
    "n_vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 200\n",
    "\n",
    "datax = []\n",
    "datay = []\n",
    "\n",
    "for i in range(seq_length, n_char, 1):\n",
    "    seq_in = raw_txt[i-seq_length : i]\n",
    "    seq_out = raw_txt[i]\n",
    "    datax.append([char_to_int[char] for char in seq_in])\n",
    "    datay.append([char_to_int[char] for char in seq_out])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99793"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_patterns = len(datax)\n",
    "n_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99793, 200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(datax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99793, 200, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping datax so that it is accepted by lstm\n",
    "\n",
    "x = np.reshape(datax, (np.shape(datax)[0], np.shape(datax)[1],1))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalizing it \n",
    "\n",
    "x = x/float(n_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99793, 36)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding of datay\n",
    "\n",
    "y = np_utils.to_categorical(datay)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first lstm layer\n",
    "model.add(LSTM(units = 256, return_sequences= True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# adding second lstm layer\n",
    "model.add(LSTM(units = 256))\n",
    "\n",
    "# final dense layer\n",
    "model.add(Dense(y.shape[1], activation = \"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoints and callbacks\n",
    "\n",
    "filepath=\"saved_model/weights-imporvement-{epoch: 02d}-{loss: .4f}-from-class.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "99793/99793 [==============================] - 6831s 68ms/step - loss: 2.8304\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.83037, saving model to saved_model/weights-imporvement- 1- 2.8304-from-class.hdf5\n",
      "Epoch 2/10\n",
      "99793/99793 [==============================] - 6515s 65ms/step - loss: 2.5399\n",
      "\n",
      "Epoch 00002: loss improved from 2.83037 to 2.53994, saving model to saved_model/weights-imporvement- 2- 2.5399-from-class.hdf5\n",
      "Epoch 3/10\n",
      "99793/99793 [==============================] - 6534s 65ms/step - loss: 2.3729\n",
      "\n",
      "Epoch 00003: loss improved from 2.53994 to 2.37288, saving model to saved_model/weights-imporvement- 3- 2.3729-from-class.hdf5\n",
      "Epoch 4/10\n",
      "99793/99793 [==============================] - 6514s 65ms/step - loss: 2.2595\n",
      "\n",
      "Epoch 00004: loss improved from 2.37288 to 2.25953, saving model to saved_model/weights-imporvement- 4- 2.2595-from-class.hdf5\n",
      "Epoch 5/10\n",
      "99793/99793 [==============================] - 6517s 65ms/step - loss: 2.1706\n",
      "\n",
      "Epoch 00005: loss improved from 2.25953 to 2.17057, saving model to saved_model/weights-imporvement- 5- 2.1706-from-class.hdf5\n",
      "Epoch 6/10\n",
      "99793/99793 [==============================] - 6528s 65ms/step - loss: 2.0954\n",
      "\n",
      "Epoch 00006: loss improved from 2.17057 to 2.09537, saving model to saved_model/weights-imporvement- 6- 2.0954-from-class.hdf5\n",
      "Epoch 7/10\n",
      "99793/99793 [==============================] - 6533s 65ms/step - loss: 2.0306\n",
      "\n",
      "Epoch 00007: loss improved from 2.09537 to 2.03064, saving model to saved_model/weights-imporvement- 7- 2.0306-from-class.hdf5\n",
      "Epoch 8/10\n",
      "99793/99793 [==============================] - 6576s 66ms/step - loss: 1.9742\n",
      "\n",
      "Epoch 00008: loss improved from 2.03064 to 1.97423, saving model to saved_model/weights-imporvement- 8- 1.9742-from-class.hdf5\n",
      "Epoch 9/10\n",
      "99793/99793 [==============================] - 12769s 128ms/step - loss: 1.9248\n",
      "\n",
      "Epoch 00009: loss improved from 1.97423 to 1.92477, saving model to saved_model/weights-imporvement- 9- 1.9248-from-class.hdf5\n",
      "Epoch 10/10\n",
      "99793/99793 [==============================] - 7580s 76ms/step - loss: 1.8768\n",
      "\n",
      "Epoch 00010: loss improved from 1.92477 to 1.87678, saving model to saved_model/weights-imporvement- 10- 1.8768-from-class.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14dbf1b98c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y, batch_size = 64, epochs = 10, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input seed:\n",
      "\" k:\n",
      "stir up the provost.\n",
      "\n",
      "marcus andronicus:\n",
      "wife kill'd: it is a dead man's errlight;\n",
      "but whiles i see the substance of his true beam\n",
      "with famous driving poor and groans, and incurable unspeaker,\n",
      "a pe \"\n"
     ]
    }
   ],
   "source": [
    "# to generate text\n",
    "\n",
    "start = np.random.randint(0,len(datax))\n",
    "pattern = datax[start]\n",
    "pattern_char = [int_to_char[val] for val in pattern]\n",
    "print(\"Input seed:\")\n",
    "print(\"\\\"\", ''.join(pattern_char), \"\\\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rtier of the sight of the sight of the sight of the sight of the sight"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "for i in range(70):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x/float(n_vocabs)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1: len(pattern)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
